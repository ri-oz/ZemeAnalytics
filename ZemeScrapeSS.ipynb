{"cells":[{"cell_type":"code","execution_count":3,"source":["import requests\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import time\n","import re\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","import pygsheets\n","import streamlit as st\n","import numpy as np\n","from datetime import datetime\n","\n","\n","#functions to get adv list from SS for all regaions from all subsites\n","\n","\n","def getUrlList(url, prefix='https://www.ss.com', postfix='sell/', tag='a', class_='a_category'):\n","    req = requests.get(url)\n","    if req.status_code != 200:\n","        print(f'Unexpected status code {req.status_code}. Stopping parse')\n","        return [] \n","    soup = BeautifulSoup(req.text, 'lxml')\n","    return [ prefix + el['href'] + postfix for el in soup.find_all(tag, class_) ]\n","    \n","    \n","\n","def processRow(row, baseurl='https://www.ss.com'):\n","    ritems = []\n","    tds = row.find_all('td')\n","    ritems.append(baseurl + tds[1].a['href'])\n","    ritems.append(tds[2].text.strip().replace('\\r','').replace('\\n', ''))\n","    for td in tds[3:-1]:\n","        ritems.append(td.text)\n","    ritems.append(int(tds[-1].text.split()[0].replace(',','')))\n","    ritems.append(tds[-1].text.split()[1])\n","    return ritems\n","\n","def processRows(rows):\n","    rowlist=[]\n","    for row in rows:\n","        rowlist.append(processRow(row))\n","    return rowlist\n","\n","\n","def getRows(url):\n","    req = requests.get(url)\n","    rows = []\n","    if req.status_code != 200:\n","        print(\"Bad Request\"+req.status_code)\n","        return\n","    soup = BeautifulSoup(req.text, 'lxml')\n","    alltrs = soup.find_all('tr')\n","    for el in alltrs:\n","        if 'id' in el.attrs and 'tr_' in el.attrs['id']:\n","            rows.append(el)\n","    rows = rows[:-1] # do not need the last one nor do need to store\n","    return rows\n","\n","\n","def processPage(url):\n","    rows = getRows(url)\n","    mylist = processRows(rows)\n","    return mylist # could return processRows(rows)\n","\n","\n","def processPages(urls):\n","    results = []\n","    for url in urls:\n","        results += processPage(url)\n","        time.sleep(0.1)\n","    return results\n","\n","\n","# base url for the scraping process\n","\n","url = \"https://www.ss.lv/lv/real-estate/plots-and-lands/\"\n","\n","\n","#list of ads to process\n","\n","mylist = processPages(getUrlList(url))\n","\n","dfmylist = pd.DataFrame(mylist)\n","\n","adw_list = dfmylist[0].tolist()\n","\n","\n","# Functions to get adv data\n","\n","def get_url_text_html(url):\n","    \n","    response = requests.get(url)\n","    soup_adv_text_html = BeautifulSoup(response.text, 'html.parser')\n","    \n","    return soup_adv_text_html\n","\n","\n","\n","\n","def get_ZemePrice(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    price_detail_soup = soup_adv_text_html.find(id=\"tdo_8\")\n","    \n","    if price_detail_soup == None:\n","         adv_price = \"NA\"\n","    else:\n","        adv_price = price_detail_soup.get_text()\n","        \n","    return adv_price\n","\n","\n","\n","\n","def get_ZemePielietojums(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    pielietojums_detail_soup = soup_adv_text_html.find(id=\"tdo_228\")\n","    \n","    if pielietojums_detail_soup == None:\n","         adv_pielietojums = \"NA\"\n","    else:\n","        adv_pielietojums = pielietojums_detail_soup.get_text()\n","        \n","    return adv_pielietojums\n","\n","\n","\n","def get_Zemeplatiba(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    platiba_detail_soup = soup_adv_text_html.find(id=\"tdo_3\")\n","    \n","    if platiba_detail_soup == None:\n","         adv_platiba = \"NA\"\n","    else:\n","        adv_platiba = platiba_detail_soup.get_text()\n","        \n","    return adv_platiba\n","\n","\n","\n","def get_ZemeKnumurs(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    Knumurs_detail_soup = soup_adv_text_html.find(id=\"tdo_1631\")\n","    \n","    if Knumurs_detail_soup == None:\n","         adv_Knumurs = \"NA\"\n","    else:\n","        adv_Knumurs = Knumurs_detail_soup.get_text()\n","        \n","    return adv_Knumurs\n","\n","\n","\n","def get_ZemePilseta(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    Pilseta_detail_soup = soup_adv_text_html.find(id=\"tdo_20\")\n","    \n","    if Pilseta_detail_soup == None:\n","         adv_Pilseta = \"NA\"\n","    else:\n","        adv_Pilseta = Pilseta_detail_soup.get_text()\n","        \n","    return adv_Pilseta\n","\n","\n","\n","def get_ZemeIela_nosaukums(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    Iela_nosaukums_detail_soup = soup_adv_text_html.find(id=\"tdo_11\")\n","    \n","    if Iela_nosaukums_detail_soup == None:\n","         adv_Iela_nosaukums = \"NA\"\n","    else:\n","        adv_Iela_nosaukums = Iela_nosaukums_detail_soup.get_text()\n","        \n","    return adv_Iela_nosaukums\n","\n","\n","\n","def get_datums(url):\n","    \n","    soup_adv_text_html = get_url_text_html(url)\n","    datums_detail_soup = soup_adv_text_html.findAll(text=re.compile('Datums:'))\n","        \n","    return datums_detail_soup\n","\n","\n","\n","def data_collection_date():\n","\n","    Todaydate = datetime.today().strftime('%Y-%m-%d')\n","\n","    return Todaydate\n","\n","\n","# Making lists of data for dataframe columns\n","\n","Price_list = [get_ZemePrice(i) for i in adw_list]\n","Iela_list = [get_ZemeIela_nosaukums(i) for i in adw_list]\n","Pilseta_list = [get_ZemePilseta(i) for i in adw_list]\n","Pielietojums_list = [get_ZemePielietojums(i) for i in adw_list]\n","Platiba_list = [get_Zemeplatiba(i) for i in adw_list]\n","dates_list = [get_datums(i) for i in adw_list]\n","Knumurs_list = [get_ZemeKnumurs(i) for i in adw_list]\n","\n","\n","# building dictionary for dataframe\n","\n","adv_detalas_dictfromlist = {'Link': adw_list, 'Pilseta': Pilseta_list, 'Iela':Iela_list, 'Platiba': Platiba_list, 'Cena': Price_list, 'Zemes Tips': Pielietojums_list, 'Zemes Numurs':Knumurs_list, 'Datums':dates_list}\n","\n","# building dataframe\n","\n","df_zeme = pd.DataFrame(adv_detalas_dictfromlist)\n","df_zeme['Datu iev.']=data_collection_date()\n","\n","# Dataframe clean up proceses\n","\n","\n","df_zeme[['Cena EUR','Cena m2']] = df_zeme['Cena'].str.split('€',n=1,expand=True)\n","df_zeme[['Platiba Daudzums','Platiba Mervieniba']] = df_zeme['Platiba'].str.split(' ',n=1,expand=True)\n","df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace('€/m²', '')\n","df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace(')', '')\n","df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace('(', '')\n","\n","df_zeme['Platiba Daudzums'] = pd.to_numeric(df_zeme['Platiba Daudzums'])\n","df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace(' ', '')\n","df_zeme['Cena EUR'] = df_zeme['Cena EUR'].str.replace(' ', '')\n","df_zeme['Cena EUR'] = pd.to_numeric(df_zeme['Cena EUR'])\n","df_zeme['Cena m2'] = pd.to_numeric(df_zeme['Cena m2'])\n","\n","del df_zeme['Platiba']\n","del df_zeme['Cena']\n","\n","\n","\n","#st.dataframe(df_zeme)\n","\n","#Writing dataframe to google sheets \n","\n","#replaces what is there if not empty,run only the first time when new file is generated\n","\n","#authorization\n","\n","gc = pygsheets.authorize(service_file='/Users/rioz/Documents/GitHub/ZemeAnalytics/research-python-gs.json')\n","\n","#open the google spreadsheet\n","\n","sh = gc.open('Py_land_data')\n","\n","#select the first sheet \n","\n","wks = sh[0]\n","\n","#update the first sheet with df, starting at cell B2.\n"," \n","wks.set_dataframe(df_zeme,(1,1))"],"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-dd124fc3db99>:229: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","  df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace(')', '')\n","<ipython-input-3-dd124fc3db99>:230: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","  df_zeme['Cena m2'] = df_zeme['Cena m2'].str.replace('(', '')\n"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}